services:
  api:
    build:
      context: ./backend
    container_name: build_commit_api
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000
    user: "${APP_UID:-1000}:${APP_GID:-1000}"
    restart: unless-stopped
    environment:
      PIPELINE_CONFIG: /app/config/pipeline.yml
      HOME: /tmp  # Required for git operations
    volumes:
      - ./config/pipeline.yml:/app/config/pipeline.yml:ro
      - ./data:/app/data
    depends_on:
      - rabbitmq
      - mongo
    ports:
      - "8000:8000"

  worker_ingest:
    build:
      context: ./backend
    container_name: build_commit_worker_ingest
    command: celery -A app.celery_app.celery_app worker --loglevel=info -Q pipeline.ingest -n ingest.%h -c 1
    user: "${APP_UID:-1000}:${APP_GID:-1000}"
    restart: unless-stopped
    environment:
      PIPELINE_CONFIG: /app/config/pipeline.yml
      HOME: /tmp  # Required for git operations
    volumes:
      - ./config/pipeline.yml:/app/config/pipeline.yml:ro
      - ./data:/app/data
    depends_on:
      - rabbitmq
      - mongo

  worker_scan:
    build:
      context: ./backend
    container_name: build_commit_worker_scan
    command: celery -A app.celery_app.celery_app worker --loglevel=info -Q pipeline.scan -n scan.%h -c 4
    user: "${APP_UID:-1000}:${APP_GID:-1000}"
    restart: unless-stopped
    environment:
      PIPELINE_CONFIG: /app/config/pipeline.yml
      HOME: /tmp  # Required for git operations
      # JVM options for the sonar-scanner binary. Tweak -Xmx/-Xms to match host resources.
      SONAR_SCANNER_OPTS: "-Xmx2g -Xms512m"
    volumes:
      - ./config/pipeline.yml:/app/config/pipeline.yml:ro
      - ./data:/app/data
    depends_on:
      - rabbitmq
      - mongo

  # worker_exports:
  #   build:
  #     context: ./backend
  #   container_name: build_commit_worker_exports
  #   command: celery -A app.celery_app.celery_app worker --loglevel=info -Q pipeline.exports -n exports.%h -c 1
  #   user: "${APP_UID:-1000}:${APP_GID:-1000}"
  #   restart: unless-stopped
  #   environment:
  #     PIPELINE_CONFIG: /app/config/pipeline.yml
  #     HOME: /tmp  # Required for git operations
  #   volumes:
  #     - ./config/pipeline.yml:/app/config/pipeline.yml:ro
  #     - ./data:/app/data
  #   depends_on:
  #     - rabbitmq
  #     - mongo

  beat:
    build:
      context: ./backend
    container_name: build_commit_beat
    command: celery -A app.celery_app.celery_app beat --loglevel=info --schedule=/app/data/celerybeat-schedule
    user: "${APP_UID:-1000}:${APP_GID:-1000}"
    restart: unless-stopped
    environment:
      PIPELINE_CONFIG: /app/config/pipeline.yml
      HOME: /tmp  # Required for git operations
    volumes:
      - ./config/pipeline.yml:/app/config/pipeline.yml:ro
      - ./data:/app/data
    depends_on:
      - rabbitmq
      - mongo

  frontend:
    build:
      context: ./frontend
    container_name: build_commit_frontend
    command: npm run start -- -H 0.0.0.0 -p 3000
    user: "${APP_UID:-1000}:${APP_GID:-1000}"
    restart: unless-stopped
    environment:
      NEXT_PUBLIC_API_BASE_URL: http://localhost:8000
    depends_on:
      - api
    ports:
      - "3000:3000"

  rabbitmq:
    image: rabbitmq:3.12-management
    container_name: build_commit_rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: pipeline
      RABBITMQ_DEFAULT_PASS: pipeline
    ports:
      - "5672:5672"
      - "15672:15672"

  mongo:
    image: mongo:6.0
    container_name: build_commit_mongo
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: travis
      MONGO_INITDB_ROOT_PASSWORD: travis
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  # Single SonarQube server - receives results from multiple parallel scanners
  sonarqube:
    image: sonarqube:latest
    container_name: sonarqube
    environment:
      SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar
      SONAR_JDBC_USERNAME: sonar
      SONAR_JDBC_PASSWORD: sonar
      SONAR_ES_BOOTSTRAP_CHECKS_DISABLE: "true"
      # Allow more concurrent connections for parallel scanner submissions
      SONAR_WEB_JAVAADDITIONALOPTS: "-Dsonar.web.http.maxThreads=100"
    volumes:
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_extensions:/opt/sonarqube/extensions
      - sonarqube_logs:/opt/sonarqube/logs
    ports:
      - "9001:9000"
    depends_on:
      - db

  # PostgreSQL for SonarQube
  db:
    image: postgres:15-alpine
    container_name: sonar_db
    environment:
      POSTGRES_USER: sonar
      POSTGRES_PASSWORD: sonar
      POSTGRES_DB: sonar
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # loki:
  #   image: grafana/loki:3.0.0
  #   container_name: loki
  #   command: -config.file=/etc/loki/local-config.yaml
  #   ports:
  #     - "3100:3100"
  #   volumes:
  #     - loki_data:/loki

  # alloy:
  #   image: grafana/alloy:latest
  #   container_name: alloy
  #   command: run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy
  #   volumes:
  #     - ./config/alloy-config.alloy:/etc/alloy/config.alloy:ro
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #     - alloy_data:/var/lib/alloy/data
  #   ports:
  #     - "12345:12345"
  #   depends_on:
  #     - loki

  # grafana:
  #   image: grafana/grafana:10.2.3
  #   container_name: grafana
  #   restart: unless-stopped
  #   environment:
  #     - GF_SECURITY_ADMIN_USER=admin
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #   ports:
  #     - "3001:3000"
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #   depends_on:
  #     - loki

volumes:
  mongo_data:
  postgres_data:
  sonarqube_data:
  sonarqube_extensions:
  sonarqube_logs:
  grafana_data:
  loki_data:
  alloy_data:
